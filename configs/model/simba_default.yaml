# Default SIMBA model architecture

# Transformer architecture
transformer:
  d_model: 256
  n_layers: 5
  n_heads: 8
  dropout: 0.1
  context_length: 100

# Embeddings
embeddings:
  dim: 512

# Model features
features:
  use_adduct: false
  use_precursor_mz: true
  use_element_wise: true
  categorical_adducts: false
  use_only_protonized_adducts: false

  # Metadata features
  use_ce: false
  use_ion_activation: false
  use_ion_method: false

# Task configuration
tasks:
  # Edit Distance task
  edit_distance:
    enabled: true
    n_classes: 6
    use_gumbel: false
    use_regression: false
    max_value: 666

    # Gumbel softmax settings
    tau_gumbel_softmax: 10
    gumbel_reg_weight: 0.1

  # MCES (Maximum Common Edge Substructure) task
  mces:
    enabled: true
    use_log_loss: false
    threshold: 20
    max_value: 40

  # Cosine similarity task
  cosine_similarity:
    enabled: true
    use_cosine_distance: true

  # Tanimoto similarity
  tanimoto:
    enabled: false

  # Molecular fingerprints
  fingerprints:
    enabled: false
    use_fingerprint: false

# Multitasking
multitasking:
  enabled: true
  learnable: true
  use_loss_weights_second_similarity: false

# Data columns (for multitasking)
data_columns:
  edit_distance: 2
  mces20: 3

# Pretraining & Loading
pretrained:
  load_pretrained: false
  load_maldi_embedder: false
  maldi_embedder_path: null

# Classification threshold
threshold_class: 0.7
